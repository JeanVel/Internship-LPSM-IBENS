{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of an estimation : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch.multiprocessing as mp\n",
    "import csv \n",
    "import sys \n",
    "import os\n",
    "from functions_optim import *\n",
    "import scipy.stats as st "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_b=torch.unique(torch.tensor(pd.read_csv(\"data_cetacea/branching_times.csv\")['x']),sorted=True)\n",
    "Time=torch.linspace(0,T_b[-1],150)\n",
    "\n",
    "f=0.8\n",
    "tree_cet=tree(T_b,Time,f,\"crown\") #define the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "estim_pdr=0.108 #pulled diversification rate estimated from the Cetacean phylogeny by M.L.\n",
    "\n",
    "l_init=torch.full_like(Time,np.random.uniform(0.01,1.5)) #initial guess for the lambda function\n",
    "m_init=l_init.clone()-estim_pdr #initial guess for the mu function\n",
    "a_init=torch.log(l_init) #for sake of positivity\n",
    "b_init=torch.log(m_init) #for sake of positivity\n",
    "\n",
    "n_iter=170 #number of iterations\n",
    "lr0=0.01 #initial learning rate\n",
    "alpha=100. #penalty parameter for the lambda function\n",
    "beta=10. #penalty parameter for the mu function\n",
    "\n",
    "pen=penalties([\"exp\",2],[\"cpm\",1],alpha,beta) #define the penalty class\n",
    "optim_init=estim_param(a_init,b_init,n_iter,lr0) #define the optimization class\n",
    "statistic=\"LTT\" #statistic to fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff :  tensor(0.1729156375)\n",
      "iteration :  0  ; mses :  426.2904968261719\n",
      "Gradient Norm :  293.2152099609375\n",
      "diff :  tensor(0.1715718955)\n",
      "iteration :  1  ; mses :  404.8511047363281\n",
      "Gradient Norm :  304.1416015625\n",
      "diff :  tensor(0.1685083061)\n",
      "iteration :  2  ; mses :  382.5522766113281\n",
      "Gradient Norm :  319.8670349121094\n",
      "diff :  tensor(0.1650826931)\n",
      "iteration :  3  ; mses :  359.4239501953125\n",
      "Gradient Norm :  332.1167907714844\n",
      "diff :  tensor(0.1606556922)\n",
      "iteration :  4  ; mses :  335.447021484375\n",
      "Gradient Norm :  334.8600158691406\n",
      "diff :  tensor(0.1517991722)\n",
      "iteration :  5  ; mses :  312.2413330078125\n",
      "Gradient Norm :  337.3689270019531\n"
     ]
    }
   ],
   "source": [
    "res=GD(optim_init,tree_cet,pen,statistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
